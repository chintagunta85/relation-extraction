{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda environment to use on nightingale: /scratch/conda_envs/elmo-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6b6ead273325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmoEmbedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "import os\n",
    "from sys import path\n",
    "path.append('..')\n",
    "import utils\n",
    "import h5py\n",
    "import numpy as np\n",
    "data_path = '/data/medg/misc/semeval_2010'\n",
    "def res(path): return os.path.join(data_path, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = ElmoEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [\"I\", \"ate\", \"an\", \"apple\", \"for\", \"breakfast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = elmo.embed_sentence(tokens)\n",
    "assert(len(vectors) == 3) # one for each layer in the ELMo output\n",
    "assert(len(vectors[0]) == len(tokens)) # the vector elements correspond with the input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.9227183e-01, -3.2613143e-01,  2.2827488e-01, ...,\n",
       "          1.7574835e-01,  2.6598686e-01, -1.0131977e-01],\n",
       "        [-6.6311550e-01,  2.9512233e-01,  6.5207249e-01, ...,\n",
       "          6.5627491e-01,  4.2394802e-01,  1.2068851e+00],\n",
       "        [ 7.9657093e-02,  1.9919696e-01, -6.9490165e-02, ...,\n",
       "          2.1669537e-02,  1.2296094e-01,  4.1095167e-03],\n",
       "        [ 1.4436811e-01,  6.7775488e-02,  3.7736315e-01, ...,\n",
       "          4.1031554e-01,  2.9029346e-01, -6.1045110e-02],\n",
       "        [-2.4150278e-01,  5.4133482e-02, -3.1142172e-01, ...,\n",
       "          4.0102762e-01, -2.6212478e-01, -4.2983246e-01],\n",
       "        [-2.3136714e-01,  2.7052855e-01,  4.4680029e-01, ...,\n",
       "          2.0299840e-01, -2.5246492e-01,  4.1547477e-02]],\n",
       "\n",
       "       [[-1.1051465e+00, -4.0921751e-01, -4.3645084e-01, ...,\n",
       "         -5.5361629e-01, -2.2313195e-01,  3.2954216e-02],\n",
       "        [ 2.3847297e-01, -2.4085957e-01,  2.2867355e-02, ...,\n",
       "          3.5999560e-01, -1.5432239e-02,  9.6235260e-02],\n",
       "        [ 6.7190811e-02, -1.4298746e-01, -3.6074769e-01, ...,\n",
       "          3.6400256e-01, -1.1032820e-03,  7.2196698e-01],\n",
       "        [ 7.5014067e-01, -7.0626277e-01,  3.9627004e-01, ...,\n",
       "         -3.5477197e-01,  5.3506863e-01,  1.1609948e+00],\n",
       "        [-1.9890222e-01, -3.6067340e-01,  2.7924365e-01, ...,\n",
       "          2.5100559e-02, -3.9890850e-01,  5.1120031e-01],\n",
       "        [-5.1222515e-01, -4.7477034e-01, -2.0949890e-01, ...,\n",
       "         -6.3179284e-03, -3.5467803e-01,  6.5792108e-01]],\n",
       "\n",
       "       [[-3.2634320e+00, -9.4477606e-01, -3.1986544e-01, ...,\n",
       "         -1.6834049e+00,  2.3847967e-02,  3.8188225e-01],\n",
       "        [-7.4718177e-01, -4.5465297e-01,  1.4126741e+00, ...,\n",
       "          3.4490252e-01,  3.6524582e-01,  6.6159058e-01],\n",
       "        [-2.3929699e-01, -1.1358548e+00, -1.0007799e-02, ...,\n",
       "         -1.9812205e-01, -1.0775579e+00,  9.9873769e-01],\n",
       "        [ 1.2281955e+00, -5.1431519e-01,  1.6688714e+00, ...,\n",
       "         -5.9785074e-01, -3.6315322e-02,  2.2921371e+00],\n",
       "        [-4.1551217e-01, -7.9405212e-01,  6.0101998e-01, ...,\n",
       "         -7.2129881e-01, -6.3341439e-01,  1.3248783e+00],\n",
       "        [-3.5665530e-01, -5.5098546e-01,  1.3024218e+00, ...,\n",
       "         -3.9886653e-01, -6.4261848e-01,  6.5832168e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dimensionality of this vector is layer in ELMO LSTM X num_of_words_in_sentence X the size of the ELMO embedding\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to incorporate ELMO into my model (well the very first thing is just to use the first layer) and then beyond that use the other layers. But in order to map a sentence to the ELMO representation (which is the larger goal), I should re-generate my pickle files to include the embedding of the sentence with it so I can finally use a linearly weighted combinations of the embeddings from the different layers of the LSTM. One important question is though, that they claim that the very first layer includes context insensitive embeddings. Does this mean that in two sentences, if I have the word \"claims,\" they would both have the same vector? Let's check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sentence = [\"The\", \"apple\", \"that\", \"I\", \"ate\", \"was\", \"not\", \"delicious\"]\n",
    "vector2 = elmo.embed_sentence(new_sentence)\n",
    "assert(len(vector2) == 3)\n",
    "assert(len(vector2[0] == len(new_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10939915, -0.1721538 ,  0.11998197, ...,  0.14708203,\n",
       "        0.6417191 , -0.5814706 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector2[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14436811,  0.06777549,  0.37736315, ...,  0.41031554,\n",
       "        0.29029346, -0.06104511], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope so the embeddings are different, so this is not the best way to generate individual word embeddings via elmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest possible way of generating embedding file similar to Glove/Senna etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the train and test file of Semeval data, get the tokenized version of the sentence and then feed in individual word to generate an embedding for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/medg/misc/semeval_2010/train.txt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_duplicate_words_from_file(filename):\n",
    "    words = []\n",
    "    with open(res(filename)) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().lower().split()\n",
    "            sentence = line[5:]\n",
    "            words.extend(sentence)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dup_words = get_duplicate_words_from_file('train.txt') + get_duplicate_words_from_file('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = list(set(dup_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# consider doing some pre processing of the data where you either turn it into a number or some range of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    vectors = elmo.embed_sentence([word])\n",
    "    assert(len(vectors) == 3) # one for each layer in the ELMo output\n",
    "    assert(len(vectors[0]) == 1) # the vector elements correspond with the input tokens\n",
    "    # grab the first layer and then write that into a file\n",
    "    vector = vectors[0][0]\n",
    "    list_a = [word]\n",
    "    list_a.extend(vector)\n",
    "    vectorlist.append(list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word = words[0]\n",
    "# vectors = elmo.embed_sentence([word])\n",
    "# assert(len(vectors) == 3) # one for each layer in the ELMo output\n",
    "# assert(len(vectors[0]) == 1) # the vector elements correspond with the input tokens\n",
    "# # grab the first layer and then write that into a file\n",
    "# vector = vectors[0][0]\n",
    "# list_a = [word]\n",
    "# list_a.extend(vector)\n",
    "# vectorlist.append(list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "vectorlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(res('elmo/elmo.layer1.txt'), 'w') as f:\n",
    "    for vector in vectorlist:\n",
    "        vectorstring = \"\"\n",
    "        for val in vector:\n",
    "            vectorstring = vectorstring + \" \" + str(val)\n",
    "        vectorstring = vectorstring.strip()\n",
    "        f.write(vectorstring + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next, work on getting all the layers of the elmo embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(filename):\n",
    "    data = open(res(filename))\n",
    "    data = utils.split_data_cut_sentence(data, 50)\n",
    "    sentences = data[0]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = get_sentences('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentences = get_sentences('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2717"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_sentences_to_txt(sentences, filename):\n",
    "    with open(res('elmo/input-sentences/'+filename), 'w') as f:\n",
    "        for sentence in sentences:\n",
    "            sentence_string = \" \".join(sentence)\n",
    "            f.write(sentence_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_sentences_to_txt(train_sentences, 'train-sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_sentences_to_txt(test_sentences, 'test-sentences.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, follow the instructions on https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md to generate the h5py file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, that does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:37, 37.34s/it]\u001b[A\n",
      "65it [01:31, 26.39s/it]\u001b[A\n",
      "129it [02:16, 18.69s/it]\u001b[A\n",
      "193it [02:59, 13.28s/it]\u001b[A\n",
      "257it [03:39,  9.49s/it]\u001b[A\n",
      "321it [04:19,  6.83s/it]\u001b[A\n",
      "385it [04:57,  4.96s/it]\u001b[A\n",
      "449it [05:38,  3.66s/it]\u001b[A\n",
      "513it [06:13,  2.73s/it]\u001b[A\n",
      "577it [06:58,  2.12s/it]\u001b[A\n",
      "641it [07:37,  1.67s/it]\u001b[A\n",
      "705it [08:12,  1.33s/it]\u001b[A\n",
      "769it [08:43,  1.08s/it]\u001b[A\n",
      "833it [09:25,  1.05it/s]\u001b[A\n",
      "897it [10:03,  1.19it/s]\u001b[A\n",
      "961it [10:35,  1.35it/s]\u001b[A\n",
      "1025it [11:18,  1.39it/s]\u001b[A\n",
      "1089it [11:46,  1.57it/s]\u001b[A\n",
      "1153it [12:18,  1.69it/s]\u001b[A\n",
      "1217it [12:52,  1.74it/s]\u001b[A\n",
      "1281it [13:33,  1.68it/s]\u001b[A\n",
      "1345it [14:09,  1.70it/s]\u001b[A\n",
      "1409it [14:47,  1.70it/s]\u001b[A\n",
      "1473it [15:43,  1.48it/s]\u001b[A\n",
      "1537it [16:17,  1.59it/s]\u001b[A\n",
      "1601it [16:53,  1.63it/s]\u001b[A\n",
      "1665it [17:31,  1.66it/s]\u001b[A\n",
      "1729it [18:05,  1.71it/s]\u001b[A\n",
      "1793it [18:53,  1.57it/s]\u001b[A\n",
      "1857it [19:26,  1.68it/s]\u001b[A\n",
      "1921it [20:00,  1.73it/s]\u001b[A\n",
      "1985it [20:38,  1.72it/s]\u001b[A\n",
      "2049it [21:27,  1.56it/s]\u001b[A\n",
      "2113it [22:05,  1.60it/s]\u001b[A\n",
      "2177it [22:44,  1.62it/s]\u001b[A\n",
      "2241it [23:20,  1.66it/s]\u001b[A\n",
      "2305it [24:02,  1.62it/s]\u001b[A\n",
      "2369it [24:38,  1.65it/s]\u001b[A\n",
      "2433it [25:24,  1.57it/s]\u001b[A\n",
      "2497it [26:08,  1.53it/s]\u001b[A\n",
      "2561it [26:52,  1.51it/s]\u001b[A\n",
      "2625it [27:37,  1.48it/s]\u001b[A\n",
      "2689it [28:23,  1.46it/s]\u001b[A\n",
      "2753it [29:01,  1.52it/s]\u001b[A\n",
      "2817it [29:38,  1.57it/s]\u001b[A\n",
      "2881it [30:25,  1.50it/s]\u001b[A\n",
      "2945it [31:02,  1.57it/s]\u001b[A\n",
      "3009it [31:40,  1.60it/s]\u001b[A\n",
      "3073it [32:22,  1.57it/s]\u001b[A\n",
      "3137it [33:01,  1.60it/s]\u001b[A\n",
      "3201it [33:37,  1.65it/s]\u001b[A\n",
      "3265it [34:15,  1.66it/s]\u001b[A\n",
      "3329it [34:51,  1.68it/s]\u001b[A\n",
      "3393it [35:29,  1.69it/s]\u001b[A\n",
      "3457it [36:05,  1.72it/s]\u001b[A\n",
      "3521it [36:39,  1.76it/s]\u001b[A\n",
      "3585it [37:20,  1.69it/s]\u001b[A\n",
      "3649it [38:11,  1.53it/s]\u001b[A\n",
      "3713it [39:05,  1.41it/s]\u001b[A\n",
      "3777it [39:44,  1.47it/s]\u001b[A\n",
      "3841it [40:41,  1.35it/s]\u001b[A\n",
      "3905it [41:27,  1.36it/s]\u001b[A\n",
      "3969it [42:19,  1.32it/s]\u001b[A\n",
      "4033it [42:54,  1.44it/s]\u001b[A\n",
      "4071it [42:54,  2.05it/s]\u001b[A\n",
      "4097it [43:39,  1.17it/s]\u001b[A\n",
      "4161it [44:18,  1.28it/s]\u001b[A\n",
      "4225it [44:49,  1.44it/s]\u001b[A\n",
      "4289it [45:34,  1.44it/s]\u001b[A\n",
      "4353it [46:31,  1.33it/s]\u001b[A\n",
      "4417it [47:10,  1.41it/s]\u001b[A\n",
      "4481it [47:52,  1.44it/s]\u001b[A\n",
      "4545it [48:33,  1.47it/s]\u001b[A\n",
      "4609it [49:27,  1.37it/s]\u001b[A\n",
      "4673it [50:13,  1.38it/s]\u001b[A\n",
      "4737it [50:55,  1.42it/s]\u001b[A\n",
      "4801it [51:43,  1.39it/s]\u001b[A\n",
      "4865it [52:15,  1.53it/s]\u001b[A\n",
      "4929it [52:59,  1.51it/s]\u001b[A\n",
      "4993it [53:34,  1.59it/s]\u001b[A\n",
      "5040it [53:34,  2.27it/s]\u001b[A\n",
      "5057it [54:08,  1.10it/s]\u001b[A\n",
      "5121it [54:43,  1.25it/s]\u001b[A\n",
      "5185it [55:26,  1.31it/s]\u001b[A\n",
      "5249it [56:05,  1.40it/s]\u001b[A\n",
      "5313it [56:37,  1.54it/s]\u001b[A\n",
      "5377it [57:17,  1.56it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "with open(res('elmo/input-sentences/train-sentences.txt')) as train_file:\n",
    "    elmo.embed_file(input_file=train_file, \n",
    "                    output_file_path = res('elmo/train-elmo-full.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:04,  4.55s/it]\u001b[A\n",
      "65it [00:09,  3.20s/it]\u001b[A\n",
      "129it [00:13,  2.26s/it]\u001b[A\n",
      "193it [00:16,  1.60s/it]\u001b[A\n",
      "257it [00:19,  1.13s/it]\u001b[A\n",
      "321it [00:22,  1.24it/s]\u001b[A\n",
      "385it [00:25,  1.73it/s]\u001b[A\n",
      "449it [00:29,  2.37it/s]\u001b[A\n",
      "513it [00:32,  3.19it/s]\u001b[A\n",
      "518it [00:33,  4.37it/s]\u001b[A\n",
      "577it [00:37,  5.41it/s]\u001b[A\n",
      "641it [00:42,  6.65it/s]\u001b[A\n",
      "705it [00:46,  7.95it/s]\u001b[A\n",
      "769it [00:50,  9.47it/s]\u001b[A\n",
      "833it [00:54, 10.88it/s]\u001b[A\n",
      "897it [00:57, 12.76it/s]\u001b[A\n",
      "961it [01:00, 14.37it/s]\u001b[A\n",
      "1025it [01:04, 15.22it/s]\u001b[A\n",
      "1089it [01:08, 15.29it/s]\u001b[A\n",
      "1153it [01:11, 16.85it/s]\u001b[A\n",
      "1161it [01:11, 20.90it/s]\u001b[A\n",
      "1217it [01:15, 17.65it/s]\u001b[A\n",
      "1281it [01:20, 16.47it/s]\u001b[A\n",
      "1284it [01:20, 16.55it/s]\u001b[A\n",
      "1345it [01:23, 17.60it/s]\u001b[A\n",
      "1409it [01:27, 16.69it/s]\u001b[A\n",
      "1473it [01:31, 16.33it/s]\u001b[A\n",
      "1537it [01:34, 17.41it/s]\u001b[A\n",
      "1601it [01:38, 17.14it/s]\u001b[A\n",
      "1665it [01:42, 17.66it/s]\u001b[A\n",
      "1729it [01:46, 16.81it/s]\u001b[A\n",
      "1793it [01:50, 16.13it/s]\u001b[A\n",
      "1857it [01:54, 16.46it/s]\u001b[A\n",
      "1921it [01:57, 17.05it/s]\u001b[A\n",
      "1926it [01:57, 19.71it/s]\u001b[A\n",
      "1985it [02:00, 19.71it/s]\u001b[A\n",
      "2049it [02:05, 18.29it/s]\u001b[A\n",
      "2113it [02:08, 18.95it/s]\u001b[A\n",
      "2177it [02:12, 16.83it/s]\u001b[A\n",
      "2241it [02:16, 17.00it/s]\u001b[A\n",
      "2305it [02:20, 16.42it/s]\u001b[A\n",
      "2369it [02:23, 17.46it/s]\u001b[A\n",
      "2433it [02:28, 16.70it/s]\u001b[A\n",
      "2497it [02:33, 15.00it/s]\u001b[A\n",
      "2561it [02:36, 16.42it/s]\u001b[A\n",
      "2625it [02:39, 16.93it/s]\u001b[A\n",
      "2689it [02:41, 20.13it/s]\u001b[A\n",
      "2695it [02:41, 23.42it/s]\u001b[A\n",
      "2717it [02:41, 16.78it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "with open(res('elmo/input-sentences/test-sentences.txt')) as test_file:\n",
    "    elmo.embed_file(input_file=test_file, \n",
    "                    output_file_path = res('elmo/test-elmo-full.hdf5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the h5py file and write it as a np array on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_elmo_embeddings(filename):\n",
    "    h5py_file = h5py.File(filename, 'r')\n",
    "    elmo_embeddings = []\n",
    "    for i in range(0, len(h5py_file) - 1):\n",
    "        embedding = h5py_file.get(str(i))\n",
    "        elmo_embeddings.append(np.array(embedding))\n",
    "    return elmo_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embedding_train = get_elmo_embeddings(res('elmo/train-elmo-full.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embedding_test = get_elmo_embeddings(res('elmo/test-elmo-full.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,17,1024) into shape (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-257-f1b7f31020b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'elmo/train-elmo-full.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melmo_embedding_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/conda_envs/elmo-generate/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0mSave\u001b[0m \u001b[0mseveral\u001b[0m \u001b[0marrays\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muncompressed\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpz\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m     \u001b[0mIf\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mno\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpz\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mare\u001b[0m \u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'arr_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metc\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpz\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/conda_envs/elmo-generate/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0man\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mArray\u001b[0m \u001b[0minterpretation\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ma\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ma\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mof\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;32mis\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mperformed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,17,1024) into shape (3)"
     ]
    }
   ],
   "source": [
    "np.save(res('elmo/train-elmo-full.npy'), elmo_embedding_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5py_file = h5py.File(\"/data/medg/misc/semeval_2010/elmo/train-elmo-full.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding = h5py_file.get(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"0\": shape (3, 17, 1024), type \"<f4\">"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 17, 1024)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embedding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(len(embedding) == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8001"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h5py_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8000 + (1 is extra) for all the sentences in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions is layers, words_in_sentences, dimensions_per_layer\n",
    "elmo_embed_train = []\n",
    "for i in range(0, len(h5py_file) - 1):\n",
    "    embedding = h5py_file.get(str(i))\n",
    "    elmo_embed_train.append(np.array(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elmo_embed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embed_train[0].shape\n",
    "first_sentence = elmo_embed_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 17, 1024)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "# because of the new line character, elmo generated embeddings for the blank line at the end. \n",
    "for i in range(0, len(elmo_embed_train)):\n",
    "    sentence = elmo_embed_train[i]\n",
    "    if sentence.shape[1] > max_len:\n",
    "        max_len = sentence.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a new embedding with the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_elmo_embed_train=[]\n",
    "for i in range(0, len(elmo_embed_train)):\n",
    "    sentence = elmo_embed_train[i]\n",
    "    num_of_words_to_pad = max_len - sentence.shape[1] # gives the length of the sentence\n",
    "    array_to_pad = np.zeros(shape=(sentence.shape[0], num_of_words_to_pad, sentence.shape[2]), dtype='float32')\n",
    "    appended_array = np.append(sentence, array_to_pad, axis=1) # appending along the sentence axis\n",
    "    new_elmo_embed_train.append(appended_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to pad the elmo_embed_train with 0's in the second dimension acc to max sentence length 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 0.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "toappend = np.zeros(shape=(3,1,1024), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended = np.append(first_sentence, toappend, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 18, 1024)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure to see with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros(shape=(3,4,2), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.ones(shape=(3,1,2), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 1.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 1.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a, b, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 17, 1024)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_embed_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next will need to see how to append to the original train array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = np.zeros((3,5), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e1 = np.ones((3,1), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = sentences, e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]]), array([[1],\n",
       "        [1],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = list(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = (x for x in zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7f85a6a72360>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sentences, e1) = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([1]), array([1]))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
