{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More accurately concept blinding and removal of punctuation, normalizing digit, stop word removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Semeval 2010 dataset, this means replacing entity words by entity1 and entity2. For DDI dataset, this means replacing the two involved drug words and the other drug words. For the i2b2 dataset, this means replacing the words by their concept names. This blinding is entirely dataset dependent and by having the replacement information present in the metadata of the original csv file generated by the converters, the pre-processing module can be entirely separated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data pre-processing code has multiple assumptions. First of all, metadata that is generated should not contain any overlaps between words within the same entity itself (for example if e1 word_index is stored as [(3,3),(3,4)] that is not allowed, but [(3,3),(4,4)] is allowed. Further, if there is overlap between e1 and e2, they have to have an exact overlap and not a partial overlap. For example e1's word_index [(1,1),(2,2)] and e2's word_index [(1,1), (3,3)] is allowed but [(1,1), (2,2)] and [(1,2)] is not allowed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from relation_extraction.data import utils\n",
    "import nltk\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "RESOURCE_PATH = \"/data/medg/misc/geeticka/relation_extraction/semeval2010\"\n",
    "indir = 'pre-processed/original/'\n",
    "outdir1 = 'pre-processed/entity_blinding/'\n",
    "outdir2 = 'pre-processed/punct_stop_digit/'\n",
    "outdir3 = 'pre-processed/punct_digit/'\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)\n",
    "from relation_extraction.data.converters.converter_semeval2010 import write_dataframe, read_dataframe,\\\n",
    "check_equality_of_written_and_read_df, write_into_txt\n",
    "# from relation_extraction.data.preprocess import replace_with_concept, replace_digit_punctuation_stop_word,\\\n",
    "# get_entity_positions_and_replacement_sentence\n",
    "from relation_extraction.data.preprocess import preprocess\n",
    "\n",
    "def makedir(outdir, res):\n",
    "    if not os.path.exists(res(outdir)):\n",
    "        os.makedirs(res(outdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good row to look at in drugbank data is 4123 df_train_drugbank.iloc[4123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the different preprocessed versions into csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_dataframe_names = ['train', 'test']\n",
    "# makedir(outdir1, res)\n",
    "# makedir(outdir2, res)\n",
    "# makedir(outdir3, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for original_df_name in original_dataframe_names:\n",
    "#     type1 = preprocess(read_dataframe, res(indir + original_df_name + '_original.csv'))\n",
    "#     type2 = preprocess(read_dataframe, res(indir + original_df_name + '_original.csv'), 2)\n",
    "#     type3 = preprocess(read_dataframe, res(indir + original_df_name + '_original.csv'), 3)\n",
    "#     write_dataframe(type1, res(outdir1 + original_df_name + '_entity_blinding.csv'))\n",
    "#     write_dataframe(type2, res(outdir2 + original_df_name + '_punct_stop_digit.csv'))\n",
    "#     write_dataframe(type3, res(outdir3 + original_df_name + '_punct_digit.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write into text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['Component-Whole(e2,e1)' 'Other' 'Instrument-Agency(e2,e1)'\n",
      " 'Member-Collection(e1,e2)' 'Cause-Effect(e2,e1)'\n",
      " 'Entity-Destination(e1,e2)' 'Content-Container(e1,e2)'\n",
      " 'Message-Topic(e1,e2)' 'Product-Producer(e2,e1)'\n",
      " 'Member-Collection(e2,e1)' 'Entity-Origin(e1,e2)' 'Cause-Effect(e1,e2)'\n",
      " 'Component-Whole(e1,e2)' 'Message-Topic(e2,e1)' 'Product-Producer(e1,e2)'\n",
      " 'Entity-Origin(e2,e1)' 'Content-Container(e2,e1)'\n",
      " 'Instrument-Agency(e1,e2)' 'Entity-Destination(e2,e1)']\n",
      "Unique relations: \t ['Component-Whole(e2,e1)' 'Other' 'Instrument-Agency(e2,e1)'\n",
      " 'Member-Collection(e1,e2)' 'Cause-Effect(e2,e1)'\n",
      " 'Entity-Destination(e1,e2)' 'Content-Container(e1,e2)'\n",
      " 'Message-Topic(e1,e2)' 'Product-Producer(e2,e1)'\n",
      " 'Member-Collection(e2,e1)' 'Entity-Origin(e1,e2)' 'Cause-Effect(e1,e2)'\n",
      " 'Component-Whole(e1,e2)' 'Message-Topic(e2,e1)' 'Product-Producer(e1,e2)'\n",
      " 'Entity-Origin(e2,e1)' 'Content-Container(e2,e1)'\n",
      " 'Instrument-Agency(e1,e2)' 'Entity-Destination(e2,e1)']\n",
      "Unique relations: \t ['Component-Whole(e2,e1)' 'Other' 'Instrument-Agency(e2,e1)'\n",
      " 'Member-Collection(e1,e2)' 'Cause-Effect(e2,e1)'\n",
      " 'Entity-Destination(e1,e2)' 'Content-Container(e1,e2)'\n",
      " 'Message-Topic(e1,e2)' 'Product-Producer(e2,e1)'\n",
      " 'Member-Collection(e2,e1)' 'Entity-Origin(e1,e2)' 'Cause-Effect(e1,e2)'\n",
      " 'Component-Whole(e1,e2)' 'Message-Topic(e2,e1)' 'Product-Producer(e1,e2)'\n",
      " 'Entity-Origin(e2,e1)' 'Content-Container(e2,e1)'\n",
      " 'Instrument-Agency(e1,e2)' 'Entity-Destination(e2,e1)']\n",
      "Unique relations: \t ['Message-Topic(e1,e2)' 'Product-Producer(e2,e1)'\n",
      " 'Instrument-Agency(e2,e1)' 'Entity-Destination(e1,e2)'\n",
      " 'Cause-Effect(e2,e1)' 'Component-Whole(e1,e2)' 'Product-Producer(e1,e2)'\n",
      " 'Member-Collection(e2,e1)' 'Other' 'Entity-Origin(e1,e2)'\n",
      " 'Content-Container(e1,e2)' 'Entity-Origin(e2,e1)' 'Cause-Effect(e1,e2)'\n",
      " 'Component-Whole(e2,e1)' 'Content-Container(e2,e1)'\n",
      " 'Instrument-Agency(e1,e2)' 'Message-Topic(e2,e1)'\n",
      " 'Member-Collection(e1,e2)' 'Entity-Destination(e2,e1)']\n",
      "Unique relations: \t ['Message-Topic(e1,e2)' 'Product-Producer(e2,e1)'\n",
      " 'Instrument-Agency(e2,e1)' 'Entity-Destination(e1,e2)'\n",
      " 'Cause-Effect(e2,e1)' 'Component-Whole(e1,e2)' 'Product-Producer(e1,e2)'\n",
      " 'Member-Collection(e2,e1)' 'Other' 'Entity-Origin(e1,e2)'\n",
      " 'Content-Container(e1,e2)' 'Entity-Origin(e2,e1)' 'Cause-Effect(e1,e2)'\n",
      " 'Component-Whole(e2,e1)' 'Content-Container(e2,e1)'\n",
      " 'Instrument-Agency(e1,e2)' 'Message-Topic(e2,e1)'\n",
      " 'Member-Collection(e1,e2)' 'Entity-Destination(e2,e1)']\n",
      "Unique relations: \t ['Message-Topic(e1,e2)' 'Product-Producer(e2,e1)'\n",
      " 'Instrument-Agency(e2,e1)' 'Entity-Destination(e1,e2)'\n",
      " 'Cause-Effect(e2,e1)' 'Component-Whole(e1,e2)' 'Product-Producer(e1,e2)'\n",
      " 'Member-Collection(e2,e1)' 'Other' 'Entity-Origin(e1,e2)'\n",
      " 'Content-Container(e1,e2)' 'Entity-Origin(e2,e1)' 'Cause-Effect(e1,e2)'\n",
      " 'Component-Whole(e2,e1)' 'Content-Container(e2,e1)'\n",
      " 'Instrument-Agency(e1,e2)' 'Message-Topic(e2,e1)'\n",
      " 'Member-Collection(e1,e2)' 'Entity-Destination(e2,e1)']\n"
     ]
    }
   ],
   "source": [
    "# for original_df_name in original_dataframe_names:\n",
    "#     type1 = read_dataframe(res(outdir1 + original_df_name + '_entity_blinding.csv'))\n",
    "#     type2 = read_dataframe(res(outdir2 + original_df_name + '_punct_stop_digit.csv'))\n",
    "#     type3 = read_dataframe(res(outdir3 + original_df_name + '_punct_digit.csv'))\n",
    "#     write_into_txt(type1, res(outdir1 + original_df_name + '_entity_blinding.txt'))\n",
    "#     write_into_txt(type2, res(outdir2 + original_df_name + '_punct_stop_digit.txt'))\n",
    "#     write_into_txt(type3, res(outdir3 + original_df_name + '_punct_digit.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the lengths of the files created is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def output_file_length(res, filename):\n",
    "#     return len(open(res(filename)).readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "# print(output_file_length(res, indir + 'train_original.txt'))\n",
    "# print(output_file_length(res, outdir1 + 'train_entity_blinding.txt'))\n",
    "# print(output_file_length(res, outdir2 + 'train_punct_stop_digit.txt'))\n",
    "# print(output_file_length(res, outdir3 + 'train_punct_digit.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717\n",
      "2717\n",
      "2717\n",
      "2717\n"
     ]
    }
   ],
   "source": [
    "# print(output_file_length(res, indir + 'test_original.txt'))\n",
    "# print(output_file_length(res, outdir1 + 'test_entity_blinding.txt'))\n",
    "# print(output_file_length(res, outdir2 + 'test_punct_stop_digit.txt'))\n",
    "# print(output_file_length(res, outdir3 + 'test_punct_digit.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from relation_extraction.data.converters.converter_semeval2010 import read_dataframe\n",
    "from relation_extraction.data.preprocess import get_new_sentence_with_entity_replacement, parse_position, \\\n",
    "entity1, entity2, entity_either, get_common_and_separate_entities, list_to_string, remove_whitespace, replace_ner as r_n\n",
    "from spacy.tokens import Doc\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataframe(res(indir + 'train' + '_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_sentence     The system as described above has its greatest...\n",
       "e1                                                        configuration\n",
       "e2                                                             elements\n",
       "relation_type                                    Component-Whole(e2,e1)\n",
       "metadata              {'e1': {'word': 'configuration', 'word_index':...\n",
       "tokenized_sentence    The system as described above has its greatest...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1: '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not set([1]).intersection(set([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok good, seems like there is no overlap across named entities in the same sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a method to check for overlap between the ner_dict that is created\n",
    "def check_for_overlap(ner_dict):\n",
    "    def expand_key(string): # a string that looks like '2:2' to [2]\n",
    "        start = int(string.split(':')[0])\n",
    "        end = int(string.split(':')[1])\n",
    "        return list(range(start, end+1))\n",
    "    expanded_keys = [expand_key(key) for key in ner_dict.keys()]\n",
    "    for i1, item in enumerate(expanded_keys):\n",
    "        for i2 in range(i1 + 1, len(expanded_keys)):\n",
    "            if set(item).intersection(expanded_keys[i2]):\n",
    "                return True # overlap is true\n",
    "        for i2 in range(0, i1):\n",
    "            if set(item).intersection(expanded_keys[i2]):\n",
    "                return True\n",
    "    return False\n",
    "check_for_overlap({'3:4': 3, '2:6': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_position('1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Helper functions for the NER replacement\n",
    "###\n",
    "def overlap_index(index1, index2):\n",
    "    def expand(index):\n",
    "        start = index[0]\n",
    "        end = index[1]\n",
    "        return list(range(start, end+1))\n",
    "    expand_index1 = expand(index1)\n",
    "    expand_index2 = expand(index2)\n",
    "    if set(expand_index1).intersection(set(expand_index2)):\n",
    "        return True\n",
    "    else: return False\n",
    "    \n",
    "# for indexes that look like (1,1) and (2,2) check if the left is fully included in the right\n",
    "def fully_included(index1, index2):\n",
    "    if index1[0] >= index2[0] and index1[1] <= index2[1]: return True\n",
    "    else: return False\n",
    "\n",
    "def beginning_overlap(index1, index2): # this is tricky when (1,1) and (2,2) are there\n",
    "    if index1[0] < index2[0] and index1[1] <= index2[1]: return True\n",
    "    else: return False\n",
    "\n",
    "def end_overlap(index1, index2): # this is tricky\n",
    "    if index1[0] >= index2[0] and index1[1] > index2[1]: return True\n",
    "    else: return False\n",
    "    \n",
    "def beginning_and_end_overlap(index1, index2):\n",
    "    if index1[0] < index2[0] and index1[1] > index2[1]: return True\n",
    "    else:\n",
    "        return False\n",
    "#else there is no overlap\n",
    "    \n",
    "def correct_entity_indexes_with_ner(ner_dict, e_index):\n",
    "    new_e_index = []\n",
    "    for i in range(len(e_index)): # we are reading tuples here\n",
    "        for key in ner_dict.keys():\n",
    "            indexes = e_index[i]\n",
    "            index2 = indexes\n",
    "            index1 = parse_position(key) # checking if ner is fully included etc\n",
    "            if not overlap(index1, index2): # don't do below if there is no overlap\n",
    "                continue\n",
    "            if beginning_overlap(index1, index2):\n",
    "                e_index[i] = (index1[0], e_index[i][1])\n",
    "            elif end_overlap(index1, index2):\n",
    "                e_index[i] = (e_index[i][0], index1[1])\n",
    "            elif beginning_and_end_overlap(index1, index2):\n",
    "                e_index[i] = (index1[0], index1[1]) # else you don't change or do anything\n",
    "    return e_index\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Facebook group was very upset by this behavior ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given all of these dictionaries, return the ner replacement dictionary\n",
    "def get_ner_replacement_dictionary(only_e1_index, only_e2_index, common_indexes, ner_dict):\n",
    "    def update_dict_with_entity(e_index, ner_repl_dict, entity_name):\n",
    "        for indexes in e_index:\n",
    "            key1 = str(indexes[0]) + ':' + str(indexes[0])\n",
    "            ner_repl_dict[key1] = {'replace_by': None, 'insert': entity_name + 'START'}\n",
    "            key2 = str(indexes[-1] + 1) + ':' + str(indexes[-1] + 1)\n",
    "            ner_repl_dict[key2] = {'replace_by': None, 'insert': entity_name + 'END'}\n",
    "        return ner_repl_dict\n",
    "    # we are going to do something different: only spans for NER will be counted, but\n",
    "    # for the ENTITYSTART and ENTITYEND, we will keep the span as what token to insert before\n",
    "    ner_repl_dict = {}\n",
    "    for key in ner_dict:\n",
    "        ner_repl_dict[key] = {'replace_by': ner_dict[key], 'insert': None}\n",
    "    ner_repl_dict = update_dict_with_entity(only_e1_index, ner_repl_dict, entity1)\n",
    "    ner_repl_dict = update_dict_with_entity(only_e2_index, ner_repl_dict, entity2)\n",
    "    ner_repl_dict = update_dict_with_entity(common_indexes, ner_repl_dict, entity_either)\n",
    "    return ner_repl_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is different from the sort_position_keys because\n",
    "# we care about sorting not just by the beginning token, but also by the length that the span contains\n",
    "def ner_sort_position_keys(ner_repl_dict): # this can potentially replace sort_position_keys\n",
    "    # but only if the application of this function does not change the preprocessed CSVs generated\n",
    "    def len_key(key):\n",
    "        pos = parse_position(key)\n",
    "        return pos[1] - pos[0] + 1\n",
    "    positions = list(ner_repl_dict.keys())\n",
    "    sorted_positions = sorted(positions, key=lambda x: (parse_position(x)[0], len_key(x)))\n",
    "    return sorted_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:1', '1:2', '1:3', '4:5']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_sort_position_keys({'1:3':3, '1:1':5, '1:2':4, '4:5':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_ner(row, check_ner_overlap=False): # similar to concept_replace, with some caveats\n",
    "    named_entities = 0\n",
    "    sentence = row.tokenized_sentence.split()\n",
    "    e1_indexes = row.metadata['e1']['word_index']\n",
    "    e2_indexes = row.metadata['e2']['word_index']\n",
    "    only_e1_indexes, only_e2_indexes, common_indexes = \\\n",
    "    get_common_and_separate_entities(e1_indexes, e2_indexes)\n",
    "#     sentence = get_new_sentence_with_entity_replacement(sentence, e1_indexes, e2_indexes)\n",
    "    tokenizedSentence = sentence # in this case lowercasing is not helpful\n",
    "    doc = Doc(nlp.vocab, words=tokenizedSentence)\n",
    "    nlp.tagger(doc)\n",
    "    nlp.parser(doc)\n",
    "    nlp.entity(doc) # run NER\n",
    "    ner_dict = {} # first test for overlaps within ner\n",
    "    for ent in doc.ents:\n",
    "        named_entities += 1\n",
    "        key = str(ent.start) + ':' + str(ent.end - 1)\n",
    "        ner_dict[key] = ent.label_\n",
    "    if check_ner_overlap and check_for_overlap(ner_dict):\n",
    "        print(\"There is overlap\", ner_dict) # only need to check this once\n",
    "    #Below code works only if there isn't overlap within ner_dict, so make sure that there isn't overlap\n",
    "    \n",
    "    # overlaps between ner label and e1 and e2 indexes are a problem. \n",
    "        # Type 1: NER overlaps with e1 or e2 in the beginning or end\n",
    "        # Here we want to keep the NER link the same but extend e1 or e2 index to the beginning or end of the\n",
    "        # NER \n",
    "        \n",
    "    print(only_e1_indexes, only_e2_indexes, common_indexes, ner_dict)\n",
    "    only_e1_indexes = correct_entity_indexes_with_ner(ner_dict, only_e1_indexes)\n",
    "    only_e2_indexes = correct_entity_indexes_with_ner(ner_dict, only_e2_indexes)\n",
    "    common_indexes = correct_entity_indexes_with_ner(ner_dict, common_indexes)\n",
    "        \n",
    "        #Type 2: NER is inside of the entity completely: At this point it should be simply ok to mention at what \n",
    "        # token to insert ENTITYstart and ENTITYend\n",
    "    ner_repl_dict = get_ner_replacement_dictionary(only_e1_indexes, only_e2_indexes, common_indexes,\n",
    "                                                  ner_dict)\n",
    "    print(ner_repl_dict)\n",
    "    print(only_e1_indexes, only_e2_indexes, common_indexes)\n",
    "    sorted_positions = ner_sort_position_keys(ner_repl_dict)\n",
    "    print('sorted_positions', sorted_positions)\n",
    "    print(sentence)\n",
    "    new_sentence = '' # this below part is buggy, shouldn't be too bad to fix \n",
    "    for i in range(len(sorted_positions)):\n",
    "        curr_pos = sorted_positions[i]\n",
    "        curr_start_pos, curr_end_pos = parse_position(curr_pos)\n",
    "        curr_dict = ner_repl_dict[curr_pos]\n",
    "        start_insert = '' if curr_dict['insert'] is None else curr_dict['insert'].upper()\n",
    "        between_replace = list_to_string(sentence[curr_start_pos: curr_end_pos + 1]) \\\n",
    "        if curr_dict['replace_by'] is None else curr_dict['replace_by']\n",
    "        if i == 0:\n",
    "            new_sentence += list_to_string(sentence[:curr_start_pos]) + ' ' + start_insert + ' ' + \\\n",
    "            between_replace + ' '\n",
    "        else:\n",
    "            prev_pos = sorted_positions[i-1]\n",
    "            _, prev_end_pos = parse_position(prev_pos)\n",
    "            middle = list_to_string(sentence[prev_end_pos+1 : curr_start_pos]) # refers to middle between prev\n",
    "            # segment and the current segment\n",
    "            if middle == '':\n",
    "                middle = ' '\n",
    "            new_sentence += middle + ' ' + start_insert + ' ' + between_replace + ' '\n",
    "            if i == len(sorted_positions) - 1 and curr_end_pos < len(sentence) - 1:\n",
    "                new_sentence += ' ' + list_to_string(sentence[curr_end_pos+1:])\n",
    "    new_sentence = remove_whitespace(new_sentence)\n",
    "    return new_sentence\n",
    "    # dictionary that we generate for sentence representation should look like:\n",
    "    # {'0:0': {'replace_by': NER, 'insert': NONE}, '1:1': {'replace_by': None, 'insert': 'ENTITYSTART'}}\n",
    "    # In this case, sorted positions should be arranged by first number but also keep in mind how many \n",
    "    # words are included in these. \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In her dentist dad 's office , with the help of her brother PERSON she finds a ESTART bottle EEND full of pulled EOTHERSTART teeth EOTHEREND .\""
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_n(df.iloc[900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(17, 17)] [(21, 21)] [] {'13:13': 'PERSON'}\n",
      "{'13:13': {'replace_by': 'PERSON', 'insert': None}, '17:17': {'replace_by': None, 'insert': 'ESTART'}, '18:18': {'replace_by': None, 'insert': 'EEND'}, '21:21': {'replace_by': None, 'insert': 'EOTHERSTART'}, '22:22': {'replace_by': None, 'insert': 'EOTHEREND'}}\n",
      "[(17, 17)] [(21, 21)] []\n",
      "sorted_positions ['13:13', '17:17', '18:18', '21:21', '22:22']\n",
      "['In', 'her', 'dentist', 'dad', \"'s\", 'office', ',', 'with', 'the', 'help', 'of', 'her', 'brother', 'Norman', 'she', 'finds', 'a', 'bottle', 'full', 'of', 'pulled', 'teeth', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"In her dentist dad 's office , with the help of her brother PERSON she finds a ESTART bottle EEND full of pulled EOTHERSTART teeth EOTHEREND .\""
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_ner(df.iloc[900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current view is that the chronic inflammation in the distal part of the stomach caused by Helicobacter pylori infection results in an increased acid production from the non - infected upper corpus region of the stomach .'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[6]['tokenized_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = 0\n",
    "df['tagged_sentence'] = df.apply(r_n, args=(False,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       The system as described above has its greatest...\n",
       "1       The ESTART child EEND was carefully wrapped an...\n",
       "2       The ESTART author EEND of a keygen uses a EOTH...\n",
       "3       A misty ESTART ridge EEND uprises from the EOT...\n",
       "4       The ESTART student EOTHERSTART association EOT...\n",
       "5       This is the sprawling ESTART complex EEND that...\n",
       "6       The current view is that the chronic ESTART in...\n",
       "7       ESTART People EEND have been moving back into ...\n",
       "8       The ESTART lawsonite EEND was contained in a E...\n",
       "9       The solute was placed inside a beaker and CARD...\n",
       "10      The CARDINAL ESTART essays EEND collected in t...\n",
       "11      Their ESTART composer EEND has sunk into EOTHE...\n",
       "12      The ORG issues an official ESTART citation EEN...\n",
       "13      The ESTART burst EEND has been caused by water...\n",
       "14      Even commercial ESTART networks EEND have move...\n",
       "15      It was a friendly ESTART call EEND to remind t...\n",
       "16      GPE - born ESTART virtuoso EEND finds harmony ...\n",
       "17      The ESTART factory EEND 's products have inclu...\n",
       "18      The girl showed a photo of apple ESTART tree E...\n",
       "19      They tried an assault of their own TIME , with...\n",
       "20      Their ESTART knowledge EEND of the power and r...\n",
       "21      She soon had a ESTART stable EEND of her own r...\n",
       "22      The ESTART singer EEND , who performed CARDINA...\n",
       "23      His intellectually engaging books and ESTART e...\n",
       "24      Poor hygiene controls , reports of a ESTART br...\n",
       "25      This sweet ESTART dress EEND is made with a EO...\n",
       "26      ESTART Suicide EEND is one of the leading caus...\n",
       "27      This ESTART article EEND gives details on DATE...\n",
       "28      We have therefore taken the initiative to conv...\n",
       "29      The ESTART timer EEND of the EOTHERSTART devic...\n",
       "                              ...                        \n",
       "7970    Then , while you relax , the ESTART chef EEND ...\n",
       "7971    However , the fact that the guinea pigs appear...\n",
       "7972    The ESTART student EEND provided a written EOT...\n",
       "7973    In order for handwashing to be effective , vig...\n",
       "7974    Mr C notes ESTART worsening EEND of seizures a...\n",
       "7975    Get a ESTART quesadilla EOTHERSTART maker EOTH...\n",
       "7976    ORG the ESTART barber EEND downed his EOTHERST...\n",
       "7977    Not too long ago , the ESTART grass EEND was f...\n",
       "7978    The punk ESTART explosion EEND cultivated the ...\n",
       "7979    The ESTART carpet EEND is made from recycled E...\n",
       "7980    This is incorrect , and when a ESTART minicab ...\n",
       "7981    A goal is like a mountain outcropping to which...\n",
       "7982    A ESTART facilitator EEND keeps the EOTHERSTAR...\n",
       "7983    Hand creams counteract ESTART dryness EEND fro...\n",
       "7984    Eye ESTART discomfort EEND from this EOTHERSTA...\n",
       "7985    The lower mark is the GPE ESTART company EEND ...\n",
       "7986    The ESTART transmitter EEND emits a constant r...\n",
       "7987    Parents also experience ESTART anxiety EEND fr...\n",
       "7988    It just so happened that the ESTART horse EEND...\n",
       "7989    In some NORP countries , including GPE , GPE a...\n",
       "7990    Using an e - prescription module in an electro...\n",
       "7991    State ESTART citizens EEND created the EOTHERS...\n",
       "7992    In chemical lasers the ESTART inversion EEND i...\n",
       "7993    The ESTART streaks EEND are from a passing EOT...\n",
       "7994    A ORG ESTART engine EEND mated with a manual t...\n",
       "7995    When the ESTART notice EEND is sent by EOTHERS...\n",
       "7996    The ESTART herbicide EEND is derived from a na...\n",
       "7997    To test this , we placed a kitchen ESTART matc...\n",
       "7998    The farmers and city officials in the region h...\n",
       "7999    The ESTART surgeon EEND cuts a small EOTHERSTA...\n",
       "Name: tagged_sentence, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tagged_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataframe(res(indir + 'test' + '_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "5       None\n",
       "6       None\n",
       "7       None\n",
       "8       None\n",
       "9       None\n",
       "10      None\n",
       "11      None\n",
       "12      None\n",
       "13      None\n",
       "14      None\n",
       "15      None\n",
       "16      None\n",
       "17      None\n",
       "18      None\n",
       "19      None\n",
       "20      None\n",
       "21      None\n",
       "22      None\n",
       "23      None\n",
       "24      None\n",
       "25      None\n",
       "26      None\n",
       "27      None\n",
       "28      None\n",
       "29      None\n",
       "        ... \n",
       "2687    None\n",
       "2688    None\n",
       "2689    None\n",
       "2690    None\n",
       "2691    None\n",
       "2692    None\n",
       "2693    None\n",
       "2694    None\n",
       "2695    None\n",
       "2696    None\n",
       "2697    None\n",
       "2698    None\n",
       "2699    None\n",
       "2700    None\n",
       "2701    None\n",
       "2702    None\n",
       "2703    None\n",
       "2704    None\n",
       "2705    None\n",
       "2706    None\n",
       "2707    None\n",
       "2708    None\n",
       "2709    None\n",
       "2710    None\n",
       "2711    None\n",
       "2712    None\n",
       "2713    None\n",
       "2714    None\n",
       "2715    None\n",
       "2716    None\n",
       "Length: 2717, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(replace_ner, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
