{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because DDI consists of entities that are split up across different parts of the sentence, their ending token is the same in the labeling, which causes problems for piecewise splitting of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, random, pandas as pd, numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append('../../../')\n",
    "from relation_extraction.data import utils\n",
    "import nltk\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "RESOURCE_PATH = \"/data/medg/misc/geeticka/relation_extraction/ddi\"\n",
    "outdir = 'pre-processed/original/piecewise-pool/'\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)\n",
    "from relation_extraction.data.converters.converter_ddi import read_dataframe, \\\n",
    "combine, flatten_list_of_tuples, rev_relation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(res(outdir)):\n",
    "    os.mkdir(res(outdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_drugbank = read_dataframe(res('pre-processed/original/' + 'train_drugbank_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_medline = read_dataframe(res('pre-processed/original/' + 'train_medline_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_drugbank = read_dataframe(res('pre-processed/original/' + 'test_drugbank_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_medline = read_dataframe(res('pre-processed/original/' + 'test_medline_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_into_txt(df, directory):\n",
    "    print(\"Unique relations: \\t\", df['relation_type'].unique())\n",
    "    null_row = df[df[\"relation_type\"].isnull()]\n",
    "    if null_row.empty:\n",
    "        idx_null_row = None\n",
    "    else:\n",
    "        idx_null_row = null_row.index.values[0]\n",
    "    with open(directory, 'w') as outfile:\n",
    "        for i in range(0, len(df)):\n",
    "            if idx_null_row is not None and i == idx_null_row:\n",
    "                continue\n",
    "            row = df.iloc[i]\n",
    "            relation = rev_relation_dict[row.relation_type]\n",
    "            metadata = row.metadata\n",
    "            e1 = flatten_list_of_tuples(metadata['e1']['word_index'])\n",
    "            e2 = flatten_list_of_tuples(metadata['e2']['word_index'])\n",
    "            common = list(set(e1).intersection(set(e2)))\n",
    "            e1 = [x for x in e1 if x not in common]\n",
    "            e2 = [x for x in e2 if x not in common]\n",
    "            e1 = sorted(e1)\n",
    "            e2 = sorted(e2)\n",
    "            tokenized_sentence = row.tokenized_sentence\n",
    "            outfile.write(str(relation) + \" \" + str(e1[0]) + \" \" + str(e1[-1]) + \" \" + \n",
    "                          str(e2[0]) + \" \" + str(e2[-1]) + \" \" + tokenized_sentence + \"\\n\")\n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['effect' 'none' 'advise' 'mechanism' 'int']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_train_drugbank, res(outdir + 'train_drugbank_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['none' 'mechanism' 'effect' 'advise' 'int']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_train_medline, res(outdir + 'train_medline_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['int' 'effect' 'none' 'mechanism' 'advise']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_test_drugbank, res(outdir + 'test_drugbank_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['none' 'effect' 'mechanism' 'advise' 'int']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_test_medline, res(outdir + 'test_medline_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(res, outdir, 'train_medline_original', 'train_drugbank_original', 'train_original.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(res, outdir, 'test_medline_original', 'test_drugbank_original', 'test_original.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
