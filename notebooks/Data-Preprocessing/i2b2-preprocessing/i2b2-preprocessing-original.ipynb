{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the i2b2 data without any blinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "sys.path.append('../../../')\n",
    "from relation_extraction.data import utils\n",
    "import nltk\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "RESOURCE_PATH = \"/data/medg/misc/geeticka/relation_extraction/i2b2\"\n",
    "outdir = 'pre-processed/original/'\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)\n",
    "from relation_extraction.data.converters.converter_i2b2 import get_filename_with_extension, \\\n",
    "get_filename_without_extension, get_concept_dictionary, get_dataset_dataframe, write_dataframe, read_dataframe,\\\n",
    "check_equality_of_written_and_read_df, write_into_txt, combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "beth_training = res('concept_assertion_relation_training_data/beth/')\n",
    "partners_training = res('concept_assertion_relation_training_data/partners/')\n",
    "test_reference = res('reference_standard_for_test_data/')\n",
    "test = res('test_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:02<00:00, 24.35it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train_beth = get_dataset_dataframe(beth_training + \"concept/\", beth_training + 'rel/', beth_training + 'txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:02<00:00, 38.94it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train_partners = get_dataset_dataframe(partners_training + \"concept/\", partners_training + \"rel/\", partners_training + 'txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:09<00:00, 27.51it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = get_dataset_dataframe(test_reference + \"concepts/\", test_reference + \"rel/\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1973"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_beth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_partners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6293"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set is significantly smaller than test set - that may be a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for empty entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_entity_rows(df):\n",
    "    empty_entity_rows = []\n",
    "    def find_empty_entity_number(row):\n",
    "        metadata = row.metadata\n",
    "        e1 = metadata['e1']['word_index']\n",
    "        e2 = metadata['e2']['word_index']\n",
    "        if not e1 or not e2:\n",
    "            empty_entity_rows.append(row.row_num)\n",
    "    temp_df = df.copy()\n",
    "    temp_df.insert(0, 'row_num', range(0, len(temp_df)))\n",
    "    temp_df.apply(find_empty_entity_number, axis=1)\n",
    "    return empty_entity_rows\n",
    "\n",
    "def get_empty_rows_array(empty_entity_rows, df):\n",
    "    empty_rows_array = []\n",
    "    for index in empty_entity_rows:\n",
    "        e1 = df.iloc[index].e1\n",
    "        e2 = df.iloc[index].e2\n",
    "        original_sentence = df.iloc[index].original_sentence\n",
    "        tokenized_sentence = df.iloc[index].tokenized_sentence\n",
    "        metadata = df.iloc[index].metadata\n",
    "        empty_rows_array.append([index, original_sentence, e1, e2, metadata, tokenized_sentence])\n",
    "    new_df = pd.DataFrame(data=empty_rows_array,    # values\n",
    "             columns=['index_original', 'original_sentence' , 'e1', 'e2', 'metadata', 'tokenized_sentence'])\n",
    "    return empty_rows_array, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_vals(df):\n",
    "    empty_entity_rows = get_empty_entity_rows(df)\n",
    "    empty_rows_array, new_df = get_empty_rows_array(empty_entity_rows, df)\n",
    "    return empty_rows_array, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_vals(df_train_beth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_vals(df_train_partners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_vals(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write into CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e1': {'word': 'chest x-ray', 'word_index': [('0', '1')]},\n",
       " 'e2': {'word': 'left lower lobe infiltrate', 'word_index': [('7', '10')]},\n",
       " 'entity_replacement': {'0:1': 'test', '7:10': 'problem'},\n",
       " 'sentence_id': '16',\n",
       " 'filename': 'record-18'}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_beth.iloc[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(res(outdir)):\n",
    "    os.makedirs(res(outdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_train_beth, res(outdir + 'train_beth_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_beth_copy = read_dataframe(res(outdir + 'train_beth_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first checks with the pd.equals method, and the other does a manual checking per column\n",
    "check_equality_of_written_and_read_df(df_train_beth, df_train_beth_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_train_partners, res(outdir + 'train_partners_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_partners_copy = read_dataframe(res(outdir + 'train_partners_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_equality_of_written_and_read_df(df_train_partners, df_train_partners_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_test, res(outdir + 'test_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = read_dataframe(res(outdir + 'test_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_equality_of_written_and_read_df(df_test, df_test_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write into txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['TeRP' 'TrAP' 'PIP' 'TrCP' 'TrWP' 'TrIP' 'TeCP' 'TrNAP']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_train_beth, res(outdir + 'train_beth_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['TeRP' 'TrAP' 'PIP' 'TeCP' 'TrCP' 'TrNAP' 'TrIP' 'TrWP']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_train_partners, res(outdir + 'train_partners_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['TrCP' 'TeRP' 'TrAP' 'PIP' 'TrWP' 'TrNAP' 'TrIP' 'TeCP']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_test, res(outdir + 'test_original.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the train data of beth and partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(res, outdir, 'train_beth_original', 'train_partners_original', 'train_original.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
