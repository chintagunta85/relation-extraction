{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the i2b2 data without any blinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, pandas as pd, numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "from collections import Counter\n",
    "sys.path.append('../../../')\n",
    "from relation_extraction.data import utils\n",
    "import nltk\n",
    "from ast import literal_eval\n",
    "import itertools\n",
    "RESOURCE_PATH = \"/data/medg/misc/geeticka/relation_extraction/i2b2\"\n",
    "outdir = 'pre-processed/original/'\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)\n",
    "from relation_extraction.data.converters.converter_i2b2 import get_dataset_dataframe, read_dataframe\n",
    "# from relation_extraction.data.converters.converter_i2b2 import get_filename_with_extension, \\\n",
    "# get_filename_without_extension, get_concept_dictionary, get_dataset_dataframe_classification, write_dataframe, read_dataframe,\\\n",
    "# check_equality_of_written_and_read_df, write_into_txt, combine, get_line_number_and_word_number, read_rel_line,\\\n",
    "# get_entity_replacement_dictionary, get_dataset_dataframe_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: figure out how to handle the experiments for the extraction vs classification case. Also need to update the eval script at this point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "beth_training = res('concept_assertion_relation_training_data/beth/')\n",
    "partners_training = res('concept_assertion_relation_training_data/partners/')\n",
    "test_reference = res('reference_standard_for_test_data/')\n",
    "test = res('test_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/73 [00:00<00:06, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message from append_existing_relations(): The relation pair  {'85:8;85:9', '85:5;85:5'} is not present in the artificial relations pair and their respective types are  treatment treatment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 60/73 [00:02<00:00, 20.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message from append_existing_relations(): The relation pair  {'74:15;74:15', '74:0;74:0'} is not present in the artificial relations pair and their respective types are  test test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:03<00:00, 21.74it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train_beth = get_dataset_dataframe(beth_training + \"concept/\", beth_training + 'rel/', beth_training + 'txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:02<00:00, 37.19it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train_partners = get_dataset_dataframe(partners_training + \"concept/\", partners_training + \"rel/\", partners_training + 'txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 223/256 [00:08<00:01, 25.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message from append_existing_relations(): The relation pair  {'158:0;158:4', '158:18;158:18'} is not present in the artificial relations pair and their respective types are  test treatment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:10<00:00, 25.39it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = get_dataset_dataframe(test_reference + \"concepts/\", test_reference + \"rel/\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5796"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_beth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4435"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_partners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19114"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set is significantly smaller than test set - that may be a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for empty entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_entity_rows(df):\n",
    "    empty_entity_rows = []\n",
    "    def find_empty_entity_number(row):\n",
    "        metadata = row.metadata\n",
    "        e1 = metadata['e1']['word_index']\n",
    "        e2 = metadata['e2']['word_index']\n",
    "        if not e1 or not e2:\n",
    "            empty_entity_rows.append(row.row_num)\n",
    "    temp_df = df.copy()\n",
    "    temp_df.insert(0, 'row_num', range(0, len(temp_df)))\n",
    "    temp_df.apply(find_empty_entity_number, axis=1)\n",
    "    return empty_entity_rows\n",
    "\n",
    "def get_empty_rows_array(empty_entity_rows, df):\n",
    "    empty_rows_array = []\n",
    "    for index in empty_entity_rows:\n",
    "        e1 = df.iloc[index].e1\n",
    "        e2 = df.iloc[index].e2\n",
    "        original_sentence = df.iloc[index].original_sentence\n",
    "        tokenized_sentence = df.iloc[index].tokenized_sentence\n",
    "        metadata = df.iloc[index].metadata\n",
    "        empty_rows_array.append([index, original_sentence, e1, e2, metadata, tokenized_sentence])\n",
    "    new_df = pd.DataFrame(data=empty_rows_array,    # values\n",
    "             columns=['index_original', 'original_sentence' , 'e1', 'e2', 'metadata', 'tokenized_sentence'])\n",
    "    return empty_rows_array, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_vals(df):\n",
    "    empty_entity_rows = get_empty_entity_rows(df)\n",
    "    empty_rows_array, new_df = get_empty_rows_array(empty_entity_rows, df)\n",
    "    return empty_rows_array, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_vals(df_train_beth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_vals(df_train_partners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Empty DataFrame\n",
       " Columns: [index_original, original_sentence, e1, e2, metadata, tokenized_sentence]\n",
       " Index: [])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_vals(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write into CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e1': {'word': 'chest x-ray', 'word_index': [('0', '1')]},\n",
       " 'e2': {'word': 'left lower lobe infiltrate', 'word_index': [('7', '10')]},\n",
       " 'entity_replacement': {'0:1': 'test', '7:10': 'problem'},\n",
       " 'sentence_id': '16',\n",
       " 'filename': 'record-18'}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_beth.iloc[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(res(outdir)):\n",
    "    os.makedirs(res(outdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_train_beth, res(outdir + 'train_beth_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_beth_copy = read_dataframe(res(outdir + 'train_beth_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first checks with the pd.equals method, and the other does a manual checking per column\n",
    "check_equality_of_written_and_read_df(df_train_beth, df_train_beth_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_train_partners, res(outdir + 'train_partners_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_partners_copy = read_dataframe(res(outdir + 'train_partners_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_equality_of_written_and_read_df(df_train_partners, df_train_partners_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframe(df_test, res(outdir + 'test_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = read_dataframe(res(outdir + 'test_original.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_equality_of_written_and_read_df(df_test, df_test_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write into txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['TeRP' 'TrAP' 'PIP' 'TrCP' 'TrWP' 'TrIP' 'PP-None' 'TrP-None' 'TeP-None'\n",
      " 'TeCP' 'TrNAP']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_train_beth, res(outdir + 'train_beth_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['TeRP' 'TrAP' 'PP-None' 'TeP-None' 'PIP' 'TeCP' 'TrP-None' 'TrCP' 'TrNAP'\n",
      " 'TrIP' 'TrWP']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_train_partners, res(outdir + 'train_partners_original.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique relations: \t ['TrCP' 'TeRP' 'TrAP' 'PIP' 'TrWP' 'PP-None' 'TrP-None' 'TrNAP' 'TrIP'\n",
      " 'TeP-None' 'TeCP']\n"
     ]
    }
   ],
   "source": [
    "write_into_txt(df_test, res(outdir + 'test_original.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the train data of beth and partners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine(res, outdir, 'train_beth_original', 'train_partners_original', 'train_original.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
