{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, random, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import relation_extraction.data.utils as utils\n",
    "import itertools\n",
    "# SEED = 1\n",
    "# np.random.seed(SEED)\n",
    "# random.seed(SEED)\n",
    "RESOURCE_PATH = \"/data/medg/misc/semeval_2010/medical-data/DDICorpus/pre-processed/extraction/\"\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(res('train.txt'))\n",
    "splitted_data_border1 = utils.split_data_cut_sentence(train_data, border_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=open(res('train.txt'))\n",
    "splitted_data_border20 = utils.split_data_cut_sentence(train_data, border_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(res('train.txt'))\n",
    "splitted_data_border50 = utils.split_data_cut_sentence(train_data, border_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(res('train.txt'))\n",
    "splitted_data_border_minus1 = utils.split_data_cut_sentence(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(splitted_data):\n",
    "    # now need to figure out how to create the csv file\n",
    "    sen = splitted_data[0]\n",
    "    rel = splitted_data[1]\n",
    "    e1 = splitted_data[2]\n",
    "    e2 = splitted_data[3]\n",
    "    data = pd.DataFrame({'sentences': sen, 'relations': rel, 'e1_pos': e1, 'e2_pos': e2}, \n",
    "                        columns=['sentences', 'relations', 'e1_pos', 'e2_pos'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_border1 = get_dataframe(splitted_data_border1)\n",
    "data_border20 = get_dataframe(splitted_data_border20)\n",
    "data_border50 = get_dataframe(splitted_data_border50)\n",
    "data_borderminus1 = get_dataframe(splitted_data_border_minus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18387"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_border50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4185"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = open(res('test.txt'))\n",
    "test_data = utils.split_data_cut_sentence(test_data, border_size=1)\n",
    "len(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closest 1/x to the test/train ratio is 1/5. If we do 5 fold split, and keep 1 of the folds as held out test data, then we have a ratio of 1/4 for dev/train which gives us a 25% split, which is close enough to the test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(data, filename1, filename2, SEED):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    print(\"seed is\", SEED)\n",
    "    N = len(data)\n",
    "    K = 5\n",
    "\n",
    "    splitter = StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED)\n",
    "    fold_indices = [indices for _, indices in splitter.split(\n",
    "        data[['sentences', 'e1_pos', 'e2_pos']].values,\n",
    "        data['relations'].values\n",
    "    )]\n",
    "\n",
    "    assert len(fold_indices) == K, \"Incorrect number of folds.\"\n",
    "    assert len(np.concatenate(fold_indices)) == N, \"Folds not comprehensive.\"\n",
    "\n",
    "    splits = []\n",
    "    for fold in range(K):\n",
    "        test_fold  = fold_indices[fold]\n",
    "        dev_fold   = fold_indices[(fold + 1) % K]\n",
    "\n",
    "        non_train_start = fold\n",
    "        non_train_end   = (fold + 2) % K\n",
    "\n",
    "        if non_train_start < non_train_end:\n",
    "            train_fold = np.concatenate(fold_indices[non_train_end:] + fold_indices[:non_train_start])\n",
    "        else: train_fold = np.concatenate(fold_indices[non_train_end:non_train_start])\n",
    "        joined = np.concatenate((train_fold, dev_fold, test_fold))\n",
    "\n",
    "        assert len(joined) == N, (\n",
    "            \"Split not comprehensive for fold {fold}:\\n\"\n",
    "            \"  len(train_fold): {train}\\n\"\n",
    "            \"  len(dev_fold): {dev}\\n\"\n",
    "            \"  len(test_fold): {test}\\n\"\n",
    "            \"  len(joined): {joined}\\n\"\n",
    "            \"  N: {N}\".format(\n",
    "                N=N, fold=fold, train=len(train_fold), dev=len(dev_fold), test=len(test_fold), joined=len(joined)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        splits.append((\n",
    "            data.iloc[train_fold],\n",
    "            data.iloc[dev_fold],\n",
    "            data.iloc[test_fold],\n",
    "        ))\n",
    "\n",
    "    assert len(splits) == K, \"Too few splits\"\n",
    "\n",
    "    #below has the dependency info with the directionalities\n",
    "    #seed_1_{K}-dep-dir-fold.pkl\n",
    "    with open(res('pickled-files/' + filename1.format(K=K)), mode='wb') as f: pickle.dump(splits, f)\n",
    "    with open(res('pickled-files/'+filename2.format(K=K)), mode='wb') as f: pickle.dump(splits, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 1\n",
      "seed is 1\n",
      "seed is 1\n",
      "seed is 1\n",
      "seed is 2\n",
      "seed is 2\n",
      "seed is 2\n",
      "seed is 2\n",
      "seed is 3\n",
      "seed is 3\n",
      "seed is 3\n",
      "seed is 3\n",
      "seed is 4\n",
      "seed is 4\n",
      "seed is 4\n",
      "seed is 4\n",
      "seed is 5\n",
      "seed is 5\n",
      "seed is 5\n",
      "seed is 5\n"
     ]
    }
   ],
   "source": [
    "for s in range(1,6):\n",
    "    seed = str(s)\n",
    "    pickle_data(data_borderminus1, 'seed_'+seed+'_{K}-fold-border_-1.pkl', 'seed_'+seed+'_{K}-fold-border_-1_py2.pkl', s)\n",
    "    pickle_data(data_border1, 'seed_'+seed+'_{K}-fold-border_1.pkl', 'seed_'+seed+'_{K}-fold-border_1_py2.pkl', s)\n",
    "    pickle_data(data_border20, 'seed_'+seed+'_{K}-fold-border_20.pkl', 'seed_'+seed+'_{K}-fold-border_20_py2.pkl', s)\n",
    "    pickle_data(data_border50, 'seed_'+seed+'_{K}-fold-border_50.pkl', 'seed_'+seed+'_{K}-fold-border_50_py2.pkl', s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
