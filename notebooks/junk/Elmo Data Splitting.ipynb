{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given the elmo embeddings pickled, generate the pickled files with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, random, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import relation_extraction.data.utils as utils\n",
    "import itertools\n",
    "import h5py\n",
    "# SEED = 1\n",
    "# np.random.seed(SEED)\n",
    "# random.seed(SEED)\n",
    "RESOURCE_PATH = \"/data/medg/misc/semeval_2010\"\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(res('train.txt'))\n",
    "splitted_data_border1 = utils.split_data_cut_sentence(train_data, border_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=open(res('train.txt'))\n",
    "splitted_data_border20 = utils.split_data_cut_sentence(train_data, border_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(res('train.txt'))\n",
    "splitted_data_border50 = utils.split_data_cut_sentence(train_data, border_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = open(res('train.txt'))\n",
    "splitted_data_border_minus1 = utils.split_data_cut_sentence(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_embeddings = utils.get_elmo_embeddings(res('elmo/train-elmo-full.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elmo_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(splitted_data, elmo_data):\n",
    "    # now need to figure out how to create the csv file\n",
    "    sen = splitted_data[0]\n",
    "    rel = splitted_data[1]\n",
    "    e1 = splitted_data[2]\n",
    "    e2 = splitted_data[3]\n",
    "    elmo_data = elmo_data[0]\n",
    "    data = pd.DataFrame({'sentences': sen, 'relations': rel, 'e1_pos': e1, 'e2_pos': e2, \\\n",
    "                         'elmo_embeddings': elmo_data}, \\\n",
    "                        columns=['sentences', 'relations', 'e1_pos', 'e2_pos', 'elmo_embeddings'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_border1 = get_dataframe(splitted_data_border1, elmo_embeddings)\n",
    "data_border20 = get_dataframe(splitted_data_border20, elmo_embeddings)\n",
    "data_border50 = get_dataframe(splitted_data_border50, elmo_embeddings)\n",
    "data_borderminus1 = get_dataframe(splitted_data_border_minus1, elmo_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(data, filename1, filename2, SEED):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    print(\"seed is\", SEED)\n",
    "    N = len(data)\n",
    "    K = 10\n",
    "\n",
    "    splitter = StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED)\n",
    "    fold_indices = [indices for _, indices in splitter.split(\n",
    "        data[['sentences', 'e1_pos', 'e2_pos', 'elmo_embeddings']].values,\n",
    "        data['relations'].values\n",
    "    )]\n",
    "\n",
    "    assert len(fold_indices) == K, \"Incorrect number of folds.\"\n",
    "    assert len(np.concatenate(fold_indices)) == N, \"Folds not comprehensive.\"\n",
    "\n",
    "    splits = []\n",
    "    for fold in range(K):\n",
    "        test_fold  = fold_indices[fold]\n",
    "        dev_fold   = fold_indices[(fold + 1) % K]\n",
    "\n",
    "        non_train_start = fold\n",
    "        non_train_end   = (fold + 2) % K\n",
    "\n",
    "        if non_train_start < non_train_end:\n",
    "            train_fold = np.concatenate(fold_indices[non_train_end:] + fold_indices[:non_train_start])\n",
    "        else: train_fold = np.concatenate(fold_indices[non_train_end:non_train_start])\n",
    "        joined = np.concatenate((train_fold, dev_fold, test_fold))\n",
    "\n",
    "        assert len(joined) == N, (\n",
    "            \"Split not comprehensive for fold {fold}:\\n\"\n",
    "            \"  len(train_fold): {train}\\n\"\n",
    "            \"  len(dev_fold): {dev}\\n\"\n",
    "            \"  len(test_fold): {test}\\n\"\n",
    "            \"  len(joined): {joined}\\n\"\n",
    "            \"  N: {N}\".format(\n",
    "                N=N, fold=fold, train=len(train_fold), dev=len(dev_fold), test=len(test_fold), joined=len(joined)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        splits.append((\n",
    "            data.iloc[train_fold],\n",
    "            data.iloc[dev_fold],\n",
    "            data.iloc[test_fold],\n",
    "        ))\n",
    "\n",
    "    assert len(splits) == K, \"Too few splits\"\n",
    "\n",
    "    #below has the dependency info with the directionalities\n",
    "    #seed_1_{K}-dep-dir-fold.pkl\n",
    "    with open(res('elmo/pickled-files/'+filename1.format(K=K)), mode='wb') as f: pickle.dump(splits, f)\n",
    "    with open(res('elmo/pickled-files/'+filename2.format(K=K)), mode='wb') as f: pickle.dump(splits, f, protocol=2)\n",
    "    #seed_1_{K}-dep-dir-fold_py2.pkl\n",
    "    # below has the dependency info without the directionalities\n",
    "    # with open(res('seed_1_{K}-dep-fold.pkl'.format(K=K)), mode='wb') as f: pickle.dump(splits, f)\n",
    "    # with open(res('seed_1_{K}-dep-fold_py2.pkl'.format(K=K)), mode='wb') as f: pickle.dump(splits, f, protocol=2)\n",
    "    # dumping old data\n",
    "    # with open(res('seed_1_{K}-fold.pkl'.format(K=K)), mode='wb') as f: pickle.dump(splits, f)\n",
    "    # with open(res('seed_1_{K}-fold_py2.pkl'.format(K=K)), mode='wb') as f: pickle.dump(splits, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/conda_envs/ontology-aided-relex/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 5\n",
      "seed is 5\n",
      "seed is 5\n"
     ]
    }
   ],
   "source": [
    "pickle_data(data_border1, 'seed_5_{K}-fold-border_1.pkl', 'seed_5_{K}-fold-border_1_py2.pkl', 5)\n",
    "pickle_data(data_border20, 'seed_5_{K}-fold-border_20.pkl', 'seed_5_{K}-fold-border_20_py2.pkl', 5)\n",
    "pickle_data(data_border50, 'seed_5_{K}-fold-border_50.pkl', 'seed_5_{K}-fold-border_50_py2.pkl', 5)\n",
    "pickle_data(data_borderminus1, 'seed_5_{K}-fold-border_-1.pkl', 'seed_5_{K}-fold-border_-1_py2.pkl', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
