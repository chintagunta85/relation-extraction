{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given the elmo embeddings hdf5, generate the cross val pickled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, random, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import relation_extraction.data.utils as utils\n",
    "import itertools\n",
    "# num folds are 10 for semeval but 5 for ddi and i2b2\n",
    "# np.random.seed(SEED)\n",
    "# random.seed(SEED)\n",
    "#TODO: replace preprocessing type with the type of preprocessing you are doing\n",
    "dataset = 'ddi' #TODO: update this\n",
    "num_folds = 5 #TODO: update this\n",
    "RESOURCE_PATH = \"/data/medg/misc/geeticka/relation_extraction/\" + dataset + \"/pre-processed/original/\"\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)\n",
    "if not os.path.exists(res('elmo/pickled-files/')):\n",
    "    os.makedirs(res('elmo/pickled-files/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(splitted_data, elmo_data):\n",
    "    # now need to figure out how to create the csv file\n",
    "    sen = splitted_data[0]\n",
    "    rel = splitted_data[1]\n",
    "    e1 = splitted_data[2]\n",
    "    e2 = splitted_data[3]\n",
    "    elmo_data = elmo_data[0]\n",
    "    data = pd.DataFrame({'sentences': sen, 'relations': rel, 'e1_pos': e1, 'e2_pos': e2, \\\n",
    "                         'elmo_embeddings': elmo_data}, \\\n",
    "                        columns=['sentences', 'relations', 'e1_pos', 'e2_pos', 'elmo_embeddings'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(data, filename1, filename2, SEED, num_folds, border_size):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    print(\"seed is\", SEED)\n",
    "    N = len(data)\n",
    "    K = num_folds\n",
    "\n",
    "    splitter = StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED)\n",
    "    fold_indices = [indices for _, indices in splitter.split(\n",
    "        data[['sentences', 'e1_pos', 'e2_pos', 'elmo_embeddings']].values,\n",
    "        data['relations'].values\n",
    "    )]\n",
    "\n",
    "    assert len(fold_indices) == K, \"Incorrect number of folds.\"\n",
    "    assert len(np.concatenate(fold_indices)) == N, \"Folds not comprehensive.\"\n",
    "\n",
    "    splits = []\n",
    "    for fold in range(K):\n",
    "        test_fold  = fold_indices[fold]\n",
    "        dev_fold   = fold_indices[(fold + 1) % K]\n",
    "\n",
    "        non_train_start = fold\n",
    "        non_train_end   = (fold + 2) % K\n",
    "\n",
    "        if non_train_start < non_train_end:\n",
    "            train_fold = np.concatenate(fold_indices[non_train_end:] + fold_indices[:non_train_start])\n",
    "        else: train_fold = np.concatenate(fold_indices[non_train_end:non_train_start])\n",
    "        joined = np.concatenate((train_fold, dev_fold, test_fold))\n",
    "\n",
    "        assert len(joined) == N, (\n",
    "            \"Split not comprehensive for fold {fold}:\\n\"\n",
    "            \"  len(train_fold): {train}\\n\"\n",
    "            \"  len(dev_fold): {dev}\\n\"\n",
    "            \"  len(test_fold): {test}\\n\"\n",
    "            \"  len(joined): {joined}\\n\"\n",
    "            \"  N: {N}\".format(\n",
    "                N=N, fold=fold, train=len(train_fold), dev=len(dev_fold), test=len(test_fold), joined=len(joined)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        splits.append((\n",
    "            data.iloc[train_fold],\n",
    "            data.iloc[dev_fold],\n",
    "            data.iloc[test_fold],\n",
    "        ))\n",
    "\n",
    "    assert len(splits) == K, \"Too few splits\"\n",
    "\n",
    "    with open(res('elmo/pickled-files/'+filename1.format(K=K, bordersize=str(border_size))), mode='wb') as f: pickle.dump(splits, f)\n",
    "    with open(res('elmo/pickled-files/'+filename2.format(K=K, bordersize=str(border_size))), mode='wb') as f: pickle.dump(splits, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_sizes = [-1, 20, 50, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d43c1e068073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitted_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melmo_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     pickle_data(data, 'seed_5_{K}-fold-border_{bordersize}_original.pkl', \n\u001b[0;32m----> 7\u001b[0;31m                 'seed_5_{K}-fold-border_{bordersize}_original_py2.pkl', 5, num_folds, border_size)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-0ae0a474f273>\u001b[0m in \u001b[0;36mpickle_data\u001b[0;34m(data, filename1, filename2, SEED, num_folds, border_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Too few splits\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'elmo/pickled-files/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbordersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mborder_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'elmo/pickled-files/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbordersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mborder_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "for border_size in border_sizes:\n",
    "    train_data = open(res('train_original.txt'))\n",
    "    splitted_data = utils.split_data_cut_sentence(train_data, border_size=border_size)\n",
    "    elmo_embeddings = utils.get_elmo_embeddings(res('elmo/train_original_border_' + str(border_size) + '.hdf5'))\n",
    "    data = get_dataframe(splitted_data, elmo_embeddings)\n",
    "    pickle_data(data, 'seed_5_{K}-fold-border_{bordersize}_original.pkl', \n",
    "                'seed_5_{K}-fold-border_{bordersize}_original_py2.pkl', 5, num_folds, border_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
