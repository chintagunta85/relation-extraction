{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given the elmo embeddings hdf5, generate the cross val pickled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, random, pandas as pd, numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import relation_extraction.data.utils as utils\n",
    "import itertools\n",
    "# num folds are 10 for semeval but 5 for ddi and i2b2\n",
    "# np.random.seed(SEED)\n",
    "# random.seed(SEED)\n",
    "#TODO: replace preprocessing type with the type of preprocessing you are doing\n",
    "dataset = 'ddi' #TODO: update this\n",
    "num_folds = 5 #TODO: update this\n",
    "preprocessing_type = 'original' #TODO: update this: in most cases, it will be original\n",
    "RESOURCE_PATH = \"/crimea/geeticka/data/relation_extraction/\" + dataset + \"/pre-processed/\" + preprocessing_type + \"/\"\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)\n",
    "if not os.path.exists(res('elmo/pickled-files/')):\n",
    "    os.makedirs(res('elmo/pickled-files/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(splitted_data, elmo_data):\n",
    "    # now need to figure out how to create the csv file\n",
    "    sen = splitted_data[0]\n",
    "    rel = splitted_data[1]\n",
    "    e1 = splitted_data[2]\n",
    "    e2 = splitted_data[3]\n",
    "    elmo_data = elmo_data[0]\n",
    "    data = pd.DataFrame({'sentences': sen, 'relations': rel, 'e1_pos': e1, 'e2_pos': e2, \\\n",
    "                         'elmo_embeddings': elmo_data}, \\\n",
    "                        columns=['sentences', 'relations', 'e1_pos', 'e2_pos', 'elmo_embeddings'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(data, filename1, filename2, SEED, num_folds, border_size):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    print(\"seed is\", SEED)\n",
    "    N = len(data)\n",
    "    K = num_folds\n",
    "\n",
    "    splitter = StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED)\n",
    "    fold_indices = [indices for _, indices in splitter.split(\n",
    "        data[['sentences', 'e1_pos', 'e2_pos', 'elmo_embeddings']].values,\n",
    "        data['relations'].values\n",
    "    )]\n",
    "\n",
    "    assert len(fold_indices) == K, \"Incorrect number of folds.\"\n",
    "    assert len(np.concatenate(fold_indices)) == N, \"Folds not comprehensive.\"\n",
    "\n",
    "    splits = []\n",
    "    for fold in range(K):\n",
    "        test_fold  = fold_indices[fold]\n",
    "        dev_fold   = fold_indices[(fold + 1) % K]\n",
    "\n",
    "        non_train_start = fold\n",
    "        non_train_end   = (fold + 2) % K\n",
    "\n",
    "        if non_train_start < non_train_end:\n",
    "            train_fold = np.concatenate(fold_indices[non_train_end:] + fold_indices[:non_train_start])\n",
    "        else: train_fold = np.concatenate(fold_indices[non_train_end:non_train_start])\n",
    "        joined = np.concatenate((train_fold, dev_fold, test_fold))\n",
    "\n",
    "        assert len(joined) == N, (\n",
    "            \"Split not comprehensive for fold {fold}:\\n\"\n",
    "            \"  len(train_fold): {train}\\n\"\n",
    "            \"  len(dev_fold): {dev}\\n\"\n",
    "            \"  len(test_fold): {test}\\n\"\n",
    "            \"  len(joined): {joined}\\n\"\n",
    "            \"  N: {N}\".format(\n",
    "                N=N, fold=fold, train=len(train_fold), dev=len(dev_fold), test=len(test_fold), joined=len(joined)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        splits.append((\n",
    "            data.iloc[train_fold],\n",
    "            data.iloc[dev_fold],\n",
    "            data.iloc[test_fold],\n",
    "        ))\n",
    "\n",
    "    assert len(splits) == K, \"Too few splits\"\n",
    "\n",
    "    with open(res('elmo/pickled-files/'+filename1.format(seed=SEED, K=K, bordersize=str(border_size))), mode='wb') as f: pickle.dump(splits, f)\n",
    "    with open(res('elmo/pickled-files/'+filename2.format(seed=SEED, K=K, bordersize=str(border_size))), mode='wb') as f: pickle.dump(splits, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# border_sizes = [-1, 20, 50, 1]\n",
    "border_sizes = [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for border_size in border_sizes:\n",
    "    train_data = open(res('train_' + preprocessing_type + '.txt'))\n",
    "    splitted_data = utils.split_data_cut_sentence(train_data, border_size=border_size)\n",
    "    elmo_embeddings = utils.get_elmo_embeddings(res('elmo/train_' + preprocessing_type + '_border_' + str(border_size) + '.hdf5'))\n",
    "    data = get_dataframe(splitted_data, elmo_embeddings)\n",
    "    pickle_data(data, 'seed_{seed}_{K}-fold-border_{bordersize}_' + preprocessing_type + '.pkl', \n",
    "                'seed_{seed}_{K}-fold-border_{bordersize}_' + preprocessing_type + '_py2.pkl', 5, \n",
    "                num_folds, border_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is 1\n",
      "seed is 2\n",
      "seed is 3\n",
      "seed is 4\n"
     ]
    }
   ],
   "source": [
    "# for seed in seeds:\n",
    "#     train_data = open(res('train_original.txt'))\n",
    "#     splitted_data = utils.split_data_cut_sentence(train_data, border_size=50)\n",
    "#     elmo_embeddings = utils.get_elmo_embeddings(res('elmo/train_original_border_50.hdf5'))\n",
    "#     data = get_dataframe(splitted_data, elmo_embeddings)\n",
    "#     pickle_data(data, 'seed_{seed}_{K}-fold-border_{bordersize}_original.pkl', \n",
    "#                 'seed_{seed}_{K}-fold-border_{bordersize}_original_py2.pkl', seed, num_folds, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
