{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import os, random, pandas as pd, numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append('../../..')\n",
    "# sys.path.append('../ddi_preprocess')\n",
    "from relation_extraction.data import utils\n",
    "import nltk\n",
    "import itertools\n",
    "from ast import literal_eval # to convert the string tuple form to an actual tuple\n",
    "RESOURCE_PATH = \"/data/medg/misc/semeval_2010/medical-data/DDICorpus\"\n",
    "outdir = 'pre-processed2/extraction/'\n",
    "def res(path): return os.path.join(RESOURCE_PATH, path)\n",
    "from relation_extraction.data.ddi_preprocess.preprocess2 import get_dataset_dataframe\n",
    "from relation_extraction.data.ddi_preprocess.preprocess2 import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_dataset_dataframe(res('Train/DrugBank/'))\n",
    "#df = get_dataset_dataframe(res('Test/test_for_ddi_extraction_task/DrugBank/'))\n",
    "#df = get_dataset_dataframe(res('Train/MedLine/'))\n",
    "#df = get_dataset_dataframe(res('Test/test_for_ddi_extraction_task/MedLine/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/569 [00:00<00:17, 31.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_files_to_read: 569  from dir:  /data/medg/misc/semeval_2010/medical-data/DDICorpus/Train/DrugBank/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 569/569 [00:05<00:00, 95.18it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train_drugbank = get_dataset_dataframe(res('Train/DrugBank/'), relation_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 18/142 [00:00<00:00, 174.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_files_to_read: 142  from dir:  /data/medg/misc/semeval_2010/medical-data/DDICorpus/Train/MedLine/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:00<00:00, 178.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# df_train_medline = get_dataset_dataframe(res('Train/MedLine/'), relation_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/158 [00:00<00:01, 131.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_files_to_read: 158  from dir:  /data/medg/misc/semeval_2010/medical-data/DDICorpus/Test/test_for_ddi_extraction_task/DrugBank/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:01<00:00, 129.16it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test_drugbank = get_dataset_dataframe(res('Test/test_for_ddi_extraction_task/DrugBank/'), relation_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 15/33 [00:00<00:00, 147.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_files_to_read: 33  from dir:  /data/medg/misc/semeval_2010/medical-data/DDICorpus/Test/test_for_ddi_extraction_task/MedLine/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 148.95it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test_medline = get_dataset_dataframe(res('Test/test_for_ddi_extraction_task/MedLine/'), relation_extraction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4308"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_drugbank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_medline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_entity_rows(df):\n",
    "    empty_entity_rows = []\n",
    "    def find_empty_entity_number(row):\n",
    "        entity_number = row.entity_number\n",
    "        e1 = entity_number[0]\n",
    "        e2 = entity_number[1]\n",
    "        if not e1 or not e2:\n",
    "            empty_entity_rows.append(row.row_num)\n",
    "    temp_df = df.copy()\n",
    "    temp_df.insert(0, 'row_num', range(0, len(temp_df)))\n",
    "    temp_df.apply(find_empty_entity_number, axis=1)\n",
    "    return empty_entity_rows\n",
    "\n",
    "def get_empty_rows_array(empty_entity_rows, df):\n",
    "    empty_rows_array = []\n",
    "    for index in empty_entity_rows:\n",
    "        e1 = df.iloc[index].e1\n",
    "        e2 = df.iloc[index].e2\n",
    "        sentence_text = df.iloc[index].sentence_text\n",
    "        tokenized_sentence = df.iloc[index].tokenized_sentence\n",
    "        entity_number = df.iloc[index].entity_number\n",
    "        empty_rows_array.append([index, e1, e2, sentence_text, tokenized_sentence, entity_number])\n",
    "    new_df = pd.DataFrame(data=empty_rows_array,    # values\n",
    "             columns=['index_original', 'e1', 'e2', 'sentence_text', 'tokenized_sentence', 'entity_number'])\n",
    "    return empty_rows_array, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empty_vals(df):\n",
    "    empty_entity_rows = get_empty_entity_rows(df)\n",
    "    empty_rows_array, new_df = get_empty_rows_array(empty_entity_rows, df)\n",
    "    return empty_rows_array, new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Empty DataFrame\n",
       " Columns: [index_original, e1, e2, sentence_text, tokenized_sentence, entity_number]\n",
       " Index: [])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_vals(df_test_drugbank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], Empty DataFrame\n",
       " Columns: [index_original, e1, e2, sentence_text, tokenized_sentence, entity_number]\n",
       " Index: [])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_vals(df_test_medline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now can write these into csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_medline.to_csv(res('pre-processed2/extraction/Test/MedLine/test-medline_partialdrugblinding.csv'), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_drugbank.to_csv(res('pre-processed2/extraction/Test/DrugBank/test-drugbank_partialdrugblinding.csv'), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_drugbank.to_csv(res('pre-processed2/extraction/Train/DrugBank/train-drugbank_partialdrugblinding.csv'), encoding='utf-8', index=False)\n",
    "# # this is only relevant to the non NER task\n",
    "# df_test_drugbank.to_csv(res('pre-processed2/extraction/Test/DrugBank/test-drugbank_partialdrugblinding.csv'), encoding='utf-8', index=False)\n",
    "# df_train_medline.to_csv(res('pre-processed2/extraction/Train/MedLine/train-medline_partialdrugblinding.csv'), encoding='utf-8', index=False)\n",
    "# df_test_medline.to_csv(res('pre-processed2/extraction/Test/MedLine/test-medline_partialdrugblinding.csv'), encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the files into .txt format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Train DrugBank, there is one sentence without a pair. Did ```find . -name \"*.xml\" | xargs grep \"Drug/Laboratory Test Interactions:\"``` for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = outdir + 'Test/MedLine/'\n",
    "filename = 'test-medline_partialdrugblinding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = pd.read_csv(res(directory+filename+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['int', 'none', 'effect', 'mechanism', 'advise'], dtype=object)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['relation_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_dict = {'advise': 0, 'effect': 1, 'mechanism': 2, 'int': 3, 'none': 4} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_row = df_copy[df_copy[\"relation_type\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "if null_row.empty:\n",
    "    idx_null_row = None\n",
    "else:\n",
    "    idx_null_row = null_row.index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(res(directory + filename+'.txt'), 'w') as outfile:\n",
    "    for i in range(0, len(df_copy)):\n",
    "        if idx_null_row is not None and i == idx_null_row:\n",
    "            continue\n",
    "        row = df_copy.iloc[i]\n",
    "        relation = relation_dict[row.relation_type]\n",
    "        entity_number = literal_eval(row.entity_number)\n",
    "        # literal eval is needed because the tuple is being stored as a string\n",
    "        e1 = entity_number[0]\n",
    "        e2 = entity_number[1]\n",
    "        tokenized_sentence = row.tokenized_sentence\n",
    "        outfile.write(str(relation) + \" \" + str(e1[0]) + \" \" + str(e1[-1]) + \" \" + \n",
    "                      str(e2[0]) + \" \" + str(e2[-1]) + \" \" + tokenized_sentence + \"\\n\")\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the train/test data of Medline and Drugbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory2 = outdir + 'Test/MedLine/'\n",
    "file2 = 'test-medline_partialdrugblinding'\n",
    "directory1 = outdir + 'Test/DrugBank/'\n",
    "file1 = 'test-drugbank_partialdrugblinding'\n",
    "outfile = outdir + 'test_partialdrugblinding.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/13613336/python-concatenate-text-files\n",
    "filenames = [res(directory1 + file1+'.txt'), res(directory2 + file2+'.txt')]\n",
    "with open(res(outfile), 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
